{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path 1 - Gemini API\n",
    "This path will guide you on the set-up and usage of Google Gemini's API.\n",
    "\n",
    "### 0. Get and store the API key\n",
    "First of all, you need to login with your google account and get an API key [here](https://aistudio.google.com/app/apikey). It is **very important** that you do not share your API key with anyone and that you do not have it in your Repository.\n",
    "\n",
    "You can keep your API key in a secure local document and access it when needed. It is common to save the key as an environmental variable so that it can be accessed by your python script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this means your API key is in plain text in your script. To avoid this, if you're using VS Code, you can add your API key to a `.env` file in your workspace root with the following line:\n",
    "\n",
    "```sh\n",
    "GEMINI_API_KEY=\"PASTE YOUR KEY HERE\"\n",
    "```\n",
    "\n",
    "Alternatively, you can use the [dot-env library](https://github.com/theskumar/python-dotenv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$GEMINI_API_KEY found\n"
     ]
    }
   ],
   "source": [
    "# You can check if the environment variable API_KEY has been set up properly by running this line\n",
    "!if [ -z $GEMINI_API_KEY ]; then echo \"\\$GEMINI_API_KEY not found\"; else echo \"\\$GEMINI_API_KEY found\"; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First simple request\n",
    "Now, you can write a simple script to see if everything is working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.genai.client.Client at 0x7636f022d5b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "# The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
    "client = genai.Client()  # here you can also pass the api_key directly using os.environ['GEMINI_API_KEY']\n",
    "\n",
    "default_model = \"gemini-2.5-flash\"\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "\n",
    "Ask the model to generate content about a random topic and print the response in text.\n",
    "\n",
    "Here is the [official documentation](https://ai.google.dev/gemini-api/docs/text-generation?lang=python#configure) to find the help you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"What is love?\" is one of humanity's most ancient and profound questions, and its answer is as multifaceted and complex as existence itself. There's no single, universally agreed-upon definition, as it manifests in countless ways and is experienced deeply personally.\n",
      "\n",
      "However, we can break down its core components and explore its various facets:\n",
      "\n",
      "**At its core, love is a complex set of emotions, behaviors, and beliefs associated with strong feelings of affection, protectiveness, warmth, and respect for another person.** It's both a feeling and an action, a state of being and a choice.\n",
      "\n",
      "Here are some key characteristics and aspects of love:\n",
      "\n",
      "1.  **Affection and Warmth:** A fundamental sense of liking, caring for, and feeling warmly towards someone.\n",
      "2.  **Care and Concern:** A genuine desire for the well-being and happiness of the other person, often leading to protective behaviors.\n",
      "3.  **Attachment and Bonding:** A deep emotional connection that creates a sense of closeness, security, and belonging.\n",
      "4.  **Desire and Attraction (especially in romantic love):** A physical, emotional, or intellectual pull towards another person.\n",
      "5.  **Respect and Admiration:** Valuing the other person's qualities, character, and individuality.\n",
      "6.  **Trust and Vulnerability:** Feeling safe enough to open up, share your true self, and rely on the other person.\n",
      "7.  **Commitment and Loyalty:** A conscious choice to maintain the relationship, stand by the person, and weather challenges together.\n",
      "8.  **Empathy and Understanding:** The ability to sense, understand, and share the feelings of another.\n",
      "9.  **Sacrifice and Selflessness:** Willingness to put the needs or happiness of the loved one before your own.\n",
      "10. **Acceptance and Forgiveness:** Loving someone for who they are, flaws and all, and being willing to forgive mistakes.\n",
      "11. **Joy and Happiness:** Love often brings immense pleasure, fulfillment, and a sense of meaning to life.\n",
      "12. **Growth:** Love can inspire personal growth, encouraging individuals to become better versions of themselves.\n",
      "\n",
      "**Different Forms of Love:**\n",
      "\n",
      "Love isn't just one thing; it takes on many forms:\n",
      "\n",
      "*   **Romantic Love (Eros):** Characterized by passion, intimacy, and commitment. It can begin with infatuation and evolve into a deeper, companionate love.\n",
      "*   **Familial Love (Storge):** The deep bond between family members (parents, children, siblings), often characterized by unconditional acceptance and a sense of belonging.\n",
      "*   **Platonic Love (Philia):** The strong affection, respect, and camaraderie found in deep friendships, devoid of romantic or sexual elements.\n",
      "*   **Self-Love:** A healthy regard for one's own well-being and happiness, essential for being able to love others effectively.\n",
      "*   **Unconditional Love (Agape):** A broad, altruistic, selfless love for humanity, nature, or a higher power, often described as divine love.\n",
      "*   **Love for Hobbies, Pets, Country, etc.:** Strong affection and passion for activities, animals, or abstract concepts that bring joy and meaning.\n",
      "\n",
      "**The Experience of Love:**\n",
      "\n",
      "Love can be exhilarating, transformative, and incredibly challenging. It often requires vulnerability, courage, and consistent effort. It can bring immense joy and profound sorrow (in cases of loss or heartbreak). It is a journey of discovery, both of the other person and of oneself.\n",
      "\n",
      "**From a Scientific Perspective:**\n",
      "\n",
      "Neuroscience shows that love activates specific brain regions and releases hormones like oxytocin (the \"bonding hormone\"), dopamine (associated with pleasure and reward), and vasopressin (linked to attachment). This suggests a biological imperative for forming deep connections.\n",
      "\n",
      "**Ultimately:**\n",
      "\n",
      "Love is deeply personal and subjective. It's often more about the ongoing experience of seeking, giving, and receiving it than it is about a static definition. It's a fundamental human need and a powerful force that binds us, motivates us, and gives meaning to our lives.\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=default_model,\n",
    "    contents=\"What is love?\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generation parameters\n",
    "\n",
    "When asking the model to generate some text, there are different parameters that you can tune to improve on the final quality of the text. [Here](https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters) is an overview of the parameters that Gemini offers. Try some of them in different context and understand how they affect the final generated text.\n",
    "\n",
    "#### Exercise 2\n",
    "\n",
    "Play with the output temperature, which controls the randomness of the generated text `temperature=0` means deterministic output, while `temperature=1` means maximum randomness (try some intermediate value too). Consider keeping the `max_output_tokens` to 50 so that the output is not too long; if you do, you should also set a low `thinking_budget` to avoid an empty response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "\n",
    "Try out different `top_k` values, which controls how many tokens the model considers for output `top_k=1` means the model considers only one token for output (the one with the highest probability) `top_k=50` means the model considers the top 50 tokens for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4\n",
    "\n",
    "The same exercise as before but now with `top_p`, which controls how the model selects tokens for output `top_p=0.1` means the model selects tokens that make up 10% of the cumulative probability mass `top_p=0.9` means the model selects tokens that make up 90% of the cumulative probability mass `top_p` filters tokens *after* applying `top_k`.\n",
    "\n",
    "Can you determine a rule of thumb as to how `top_k` and `top_p` affect the output results? (If you can't try to push the values to extreme values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add images to the prompt\n",
    "\n",
    "#### Exercise 5\n",
    "Gemini, beside text also accepts images (and videos). Try prompting it with one. Choose an interesting image and prompt the model with a query about it.\n",
    "\n",
    "You can use the [official documentation](https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-images).\n",
    "\n",
    "Use [PIL](https://pillow.readthedocs.io/en/stable/) to load an image. It should already be present in the Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "IMAGE_PATH = \"./data/engineer_fitting_prosthetic_arm.jpg\"\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Retrieval Augmented Generation (RAG)\n",
    "\n",
    "#### Exercise 6\n",
    "\n",
    "Depending on the application of the project, you might need to extract text from given documents and include it as additional context. This becomes especially relevant if you have many documents that cannot possibly fit into the model's context window. To more easily implement a RAG pipeline we recommend the use of one of these libraries: [LangChain](https://python.langchain.com/v0.2/docs/introduction/), [LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/), [Haystack](https://docs.haystack.deepset.ai/docs/intro).\n",
    "\n",
    "For the solution of this lab we will use *LangChain*.\n",
    "\n",
    "It can be useful to split this exercise into these steps:\n",
    "1. Read one or more documents using pdfminer\n",
    "2. Split the documents into small chunks\n",
    "3. Get and store the embeddings for each chunks\n",
    "5. Given a query, retrieve the most relevant chunk(s) and appropriately prompt your LLM\n",
    "\n",
    "**NOTE:** if you try to embed too many documents at once or too large documents you may run into rate limits. Possible solutions: \n",
    "* Reduce the number of chunks and/or their size\n",
    "* Look at the HF version of this lab and use a local embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # langchain expects gemini's api key to be in the environment variable GOOGLE_API_KEY, use os to set it\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings  # get embeddings from Gemini\n",
    "from langchain_community.vectorstores import FAISS  # \"db\" to store and retrieve embeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # split long documents\n",
    "from pdfminer.high_level import extract_text  # extract text from pdfs\n",
    "\n",
    "DOC_PATH = \"./data/chain_of_thought_prompting.pdf\"\n",
    "\n",
    "# Suppose a user query\n",
    "USER_QUERY = \"What is CoT?\"\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Explore on your own\n",
    "Gemini offers a bigger range of capabilities than those provided here, begin able to automatically handle multi-turn chats is one of them. Explore them on your own!\n",
    "\n",
    "#### Exercise 7\n",
    "Explore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create a user interface\n",
    "\n",
    "#### Exercise 8\n",
    "Since you are trying to build a complete application, you also need a nice user interface that interacts with the model. There are various libraries available for this purpose. Notably: [gradio](https://www.gradio.app/docs/gradio/interface) and [chat UI](https://huggingface.co/docs/chat-ui/index). For the solution of this lab, we will use gradio.\n",
    "\n",
    "Gradio has pre-defined input/output blocks that are automatically inserted in the interface. You only need to provide an appropriate function that takes all the inputs and returns the relevant output. See documentation [here](https://www.gradio.app/docs/gradio/interface).\n",
    "\n",
    "Use a ChatInterface to create a chatbot UI that let's you discuss with Gemini, then add multimodal capabilities for both Gradio and Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# This part closes the demo server if it is already running (which\n",
    "# happens easily in notebooks) and prevents you from opening multiple\n",
    "# servers at the same time.\n",
    "if \"demo\" in locals() and demo.is_running:\n",
    "    demo.close()\n",
    "\n",
    "# Edit the parameters below\n",
    "chats = {}  # store the chat history for each user (suppose multiple users)\n",
    "\n",
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
